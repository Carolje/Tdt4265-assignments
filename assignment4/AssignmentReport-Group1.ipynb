{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 Report - Group 112"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an outline for your report to ease the amount of work required to create your report. Jupyter notebook supports markdown, and I recommend you to check out this [cheat sheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet). If you are not familiar with markdown.\n",
    "\n",
    "Before delivery, **remember to convert this file to PDF**. You can do it in two ways:\n",
    "1. Print the webpage (ctrl+P or cmd+P)\n",
    "2. Export with latex. This is somewhat more difficult, but you'll get somehwat of a \"prettier\" PDF. Go to File -> Download as -> PDF via LaTeX. You might have to install nbconvert and pandoc through conda; `conda install nbconvert pandoc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1a)\n",
    "\n",
    "The intersection over the union (IoU) is a measure of how well two areas overlap (the closer to one, the more overlap). It is done by taking the ratio of the area of intersection and the area of the union. That is for two areas A and B the IoU will be, \n",
    "$\\text{IoU} = \\frac{A \\cap B}{A \\cup B}$.\n",
    "The bounding box $A$ can be represented by the two coordinate pairs $(x_{A1}, y_{A1})$ and $(x_{A2}, y_{A2})$, and B by $(x_{B1}, y_{B1})$ and $(x_{B2}, y_{B2})$. Meaning that the area of A is $(x_{A2} - x_{A2})\\cdot (y_{A1} - y_{A2})$ and the area of B is $(x_{B2} - x_{B2})\\cdot (y_{B1} - y_{B2})$\n",
    "then for the figure below, the IoU will be,\n",
    "\n",
    "\\begin{align*}\n",
    "\\text{IoU} &= \\frac{A\\cap B}{A\\cup B} = \\frac{A\\cap B}{A + B - A\\cap B}\\\\\n",
    "&=\\frac{(x_{A2} - x_{B1})\\cdot (y_{B1} - y_{A2})}{\n",
    "(x_{A2} - x_{A2})\\cdot (y_{A1} - y_{A2}) + (x_{B2} - x_{B2})\\cdot (y_{B1} - y_{B2}) - (x_{A2} - x_{B1})\\cdot (y_{B1} - y_{A1})\n",
    "}\n",
    "\\end{align*}\n",
    "![](IoUdrawing.jpg)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1b)\n",
    "A true positive (TP) is when our classifiser correctly classify the data to the correct class (positve class), while a negative positive (TN) is when our classifiser correctly classify the data to not be in a class.\n",
    "The precision is the rate between all true positive findings for a given class and all positive findings (true and false) for that same class, that is the precentage of correct classifications for that class and it is given by,\n",
    "$\\text{Precision } = \\frac{TP}{TP + FP}$.\n",
    "Recall is the rate between all true positive findings for a class and all instances of that class, in other words recall is a measure of how well our classifiser find all positive cases of a class and it is then given by\n",
    "$\\text{Recall } = \\frac{TP}{TP + FN}$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1c)\n",
    "\n",
    "The calculation for the mAP is shown in the picture below\n",
    "![](task2/mAPcalc.jpg)\n",
    "Thus the for these PR-curves are $0.641$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "### Task 2f)\n",
    "Of this PR-curve we get an mAP of 0.907 which is slightly higher than it should be, but within reasonable limits.\n",
    "![](task2/precision_recall_curve.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3a)\n",
    "The filtering method is called for non-maximum suppression (nms) and is done with a jacard overlap threshold.\n",
    "\n",
    "### Task 3b)\n",
    "TRUE\n",
    "\n",
    "### Task 3c)\n",
    "Diffrent sizes of bounding boxes allows for detections of objects with different shapes, so a set of default bounding boxes applied at the same anchor lets us identify different objects more efficiently.\n",
    "\n",
    "\n",
    "### Task 3d)\n",
    "The diffrence between SSD and YOLOv1/v2 is that YOLO does not use a set of predefined default bounding boxes, but instead uses K-means clustering on the training-data to propose a set of default bounding boxes. This increases the training time of YOLOv1/v2. SSD also differ from YOLOv1/v2 in that it is able to detect objects of diffrent sizes more effciently since it has multi-scale feature maps, while YOLO only has single scale feature maps. SSD also uses a convolutional filter in order to predict the offset to the default bounding boxes, wheras YOLOv1/v2 uses a fully connected layer to do this. Lastly, the matching strategy is the different as YOLOv1 matches the prediction with ground truth based soley on the highest IOU while SSD uses nms with jacard overlap.\n",
    "\n",
    "### Task 3e)\n",
    "We have $38\\times 38\\times 6=8664$ bounding boxes as we have $38 \\times 38$ locactions and at each location we will have $6$ boxes.\n",
    "\n",
    "### Task 3f)\n",
    "Using a similar approach as in the previous subtask, at each feature map we will have $H \\times W \\times 6$ anchor boxes, thus in total we will get the sum of all anchor boxes in each feature map which is\n",
    "\n",
    "$$(38 \\times 38 +19 \\times 19 + 10 \\times 10 + 5 \\times 5 + 3 \\times 3 + 1 \\times 1)\\times 6=11640$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "The plot for total loss\n",
    "\n",
    "![](4b_total_loss.png)\n",
    "\n",
    "Our mAP for 6000 iterations are $0.7256$.\n",
    "\n",
    "## Task 4c)\n",
    "To improve teh accuracy of our model we first did some data augmentation where we flipped some images horizontally, rotated some of the images and we used colorjitter. This improved the learning for the first 3000 iterations but had little effect on the mAP around 10000 iterations. Then we implemented a new $75 \\times 75$ output layer before the other layers. So our new structure is \n",
    "| Is output                 | Layer Type | Number of filters  | Stride |\n",
    "|---------------------------|------------|--------------------|--------|\n",
    "|                           | Conv2D     |         32         |    1   |\n",
    "|                           | ReLU       |          -         |    -   |\n",
    "|                           | MaxPool2D  |          -         |    2   |\n",
    "|                           | Conv2D     |         64         |    1   |\n",
    "|                           | ReLU       |          -         |    -   |\n",
    "|                           | MaxPool2D  |          -         |    2   |\n",
    "|                           | Conv2D     |         64         |    1   |\n",
    "|                           | ReLU       |          -         |    -   |\n",
    "|                           | Conv2D     | output_channels[0] |    1   |\n",
    "| Yes - Resolution: 75 x 75 | ReLU       |          -         |    -   |\n",
    "|                           | ReLU       |          -         |    -   |\n",
    "|                           | Conv2D     |         128        |    1   |\n",
    "|                           | ReLU       |          -         |    -   |\n",
    "|                           | Conv2D     | output_channels[1] |    2   |\n",
    "| Yes - Resolution: 38 x 38 | ReLU       |          -         |    -   |\n",
    "|                           | ReLU       |          -         |    -   |\n",
    "|                           | Conv2D     |         128        |    1   |\n",
    "|                           | ReLU       |          -         |    -   |\n",
    "|                           | Conv2D     | output_channels[2] |    2   |\n",
    "| Yes - Resolution: 19 x 19 | ReLU       |          -         |    -   |\n",
    "|                           | ReLU       |          -         |    -   |\n",
    "|                           | Conv2D     |         256        |    1   |\n",
    "|                           | ReLU       |          -         |    -   |\n",
    "|                           | Conv2D     | output_channels[3] |    2   |\n",
    "| Yes - Resolution: 10 x 10 | ReLU       |          -         |    -   |\n",
    "|                           | ReLU       |          -         |    -   |\n",
    "|                           | Conv2D     |         128        |    1   |\n",
    "|                           | ReLU       |          -         |    -   |\n",
    "|                           | Conv2D     | output_channels[4] |    2   |\n",
    "| Yes - Resolution: 5 x 5   | ReLU       |          -         |    -   |\n",
    "|                           | ReLU       |          -         |    -   |\n",
    "|                           | Conv2D     |         128        |    1   |\n",
    "|                           | ReLU       |          -         |    -   |\n",
    "|                           | Conv2D     | output_channels[5] |    2   |\n",
    "| Yes - Resolution: 3 x 3   | ReLU       |          -         |    -   |\n",
    "|                           | ReLU       |          -         |    -   |\n",
    "|                           | Conv2D     |         128        |    1   |\n",
    "|                           | ReLU       |          -         |    -   |\n",
    "|                           | Conv2D     | output_channels[6] |    1   |\n",
    "| Yes - Resolution: 1 x 1   | ReLU       |          -         |    -   |\n",
    "\n",
    "This new structure gave a mAP of $0.9361$ at 10K gradient descent iterations. \n",
    "\n",
    "## Task 4d)\n",
    "FILL IN ANSWER. \n",
    "\n",
    "\n",
    "## Task 4e)\n",
    "FILL IN ANSWER. \n",
    "\n",
    "\n",
    "## Task 4f)\n",
    "FILL IN ANSWER. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tdt4265",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
